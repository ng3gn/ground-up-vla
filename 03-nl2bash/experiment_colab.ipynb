{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZWC_MgV0tFV"
   },
   "source": [
    "# NL2Bash Depth Experiment — Colab Notebook\n",
    "\n",
    "This notebook runs depth experiments comparing PyTorch and TorchLite models on the NL2Bash dataset.\n",
    "\n",
    "**Features:**\n",
    "- Train transformer models at various depths\n",
    "- Plot loss curves and final metrics\n",
    "- Compute exact match accuracy\n",
    "- Save results to Google Drive\n",
    "\n",
    "**Run time estimates:**\n",
    "- PyTorch (all depths): ~30-60 min on GPU\n",
    "- TorchLite (depth=1): ~5 min on CPU\n",
    "- Both experiments: ~1 hour total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H5_2Oq40tFW"
   },
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kD_8R8h80tFW"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q matplotlib numpy\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_C_K4Kz0tFX"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional but recommended for saving results)\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "print(\"✓ Google Drive mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SX7cX2gP0tFX"
   },
   "outputs": [],
   "source": [
    "# Clone or download the nl2bash project\n",
    "import os\n",
    "os.chdir('/content')\n",
    "\n",
    "# Option 1: Clone from git (if available)\n",
    "# !git clone https://github.com/your-repo/nl2bash.git\n",
    "\n",
    "# Option 2: Upload files manually or use Drive\n",
    "# For now, we'll create the necessary structure\n",
    "\n",
    "PROJECT_DIR = '/content/nl2bash'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(f\"✓ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nVJH_cK0tFX"
   },
   "source": [
    "## 2. Copy Project Files from Drive or Upload\n",
    "\n",
    "**Choose one approach:**\n",
    "- **Option A:** Copy from Google Drive (if you've uploaded the project)\n",
    "- **Option B:** Upload ZIP file and extract\n",
    "- **Option C:** Use the cell below to set up minimal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vLDdXRl0tFY"
   },
   "outputs": [],
   "source": [
    "# OPTION A: Copy from Google Drive\n",
    "# Adjust the path to where your nl2bash project is stored\n",
    "# import shutil\n",
    "# shutil.copytree('/content/drive/MyDrive/path/to/nl2bash', '/content/nl2bash', dirs_exist_ok=True)\n",
    "\n",
    "# OPTION B: Upload from local machine\n",
    "# Use the file upload widget in Colab's file browser\n",
    "\n",
    "# OPTION C: We'll assume files are already in place\n",
    "print(\"Files should be in:\", PROJECT_DIR)\n",
    "print(\"Required files:\")\n",
    "print(\"  - vocab.py\")\n",
    "print(\"  - tokenizer.py\")\n",
    "print(\"  - dataset.py\")\n",
    "print(\"  - main.py\")\n",
    "print(\"  - model/transformer_full.py\")\n",
    "print(\"  - model/transformer_lite.py\")\n",
    "print(\"  - data/ (directory with vocab and data files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX3j7yAj0tFY"
   },
   "source": [
    "## 3. Verify Setup\n",
    "\n",
    "Check that all required files are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f_8XT1D0tFY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "required_files = [\n",
    "    'vocab.py',\n",
    "    'tokenizer.py',\n",
    "    'dataset.py',\n",
    "    'main.py',\n",
    "    'model/transformer_full.py',\n",
    "    'model/transformer_lite.py',\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for f in required_files:\n",
    "    path = os.path.join(PROJECT_DIR, f)\n",
    "    if os.path.exists(path):\n",
    "        print(f\"✓ {f}\")\n",
    "    else:\n",
    "        print(f\"✗ {f}\")\n",
    "        missing.append(f)\n",
    "\n",
    "if missing:\n",
    "    print(f\"\\n⚠️  Missing files: {missing}\")\n",
    "    print(\"Please upload or copy the project files first.\")\n",
    "else:\n",
    "    print(\"\\n✓ All required files present!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz-7a3c30tFY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = os.path.join(PROJECT_DIR, 'data')\n",
    "required_data = [\n",
    "    'shared_vocab.txt',\n",
    "    'all.nl',\n",
    "    'all.cm',\n",
    "]\n",
    "\n",
    "print(\"Data files:\")\n",
    "missing_data = []\n",
    "for f in required_data:\n",
    "    path = os.path.join(data_dir, f)\n",
    "    if os.path.exists(path):\n",
    "        size = os.path.getsize(path) / 1024 / 1024\n",
    "        print(f\"✓ {f} ({size:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"✗ {f}\")\n",
    "        missing_data.append(f)\n",
    "\n",
    "if missing_data:\n",
    "    print(f\"\\n⚠️  Missing data files: {missing_data}\")\n",
    "    print(\"Please upload the data directory.\")\n",
    "else:\n",
    "    print(\"\\n✓ All data files present!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yy3SQK_0tFZ"
   },
   "source": [
    "## 4. Import Modules & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKkPFT9x0tFZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project directory to path\n",
    "sys.path.insert(0, PROJECT_DIR)\n",
    "sys.path.insert(0, os.path.dirname(PROJECT_DIR))  # For torchlite imports\n",
    "\n",
    "from vocab import Vocabulary\n",
    "from tokenizer import NL2BashTokenizer\n",
    "from dataset import NL2BashDataset, create_pytorch_dataloader, create_torchlite_dataloader\n",
    "\n",
    "print(\"✓ All modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6C0w-sZ0tFZ"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PYTORCH_CONFIG = {\n",
    "    'd_model': 128,\n",
    "    'n_heads': 1,\n",
    "    'd_ff': 512,\n",
    "    'batch_size': 16,\n",
    "    'lr': 0.0001,\n",
    "    'n_epochs': 20,\n",
    "    'depths': [1, 2, 4, 8, 16],\n",
    "    'dropout': 0.0,\n",
    "    'max_len': 128,\n",
    "}\n",
    "\n",
    "TORCHLITE_CONFIG = {\n",
    "    'd_model': 128,\n",
    "    'n_heads': 1,\n",
    "    'd_ff': 512,\n",
    "    'batch_size': 16,\n",
    "    'lr': 0.001,\n",
    "    'n_epochs': 3,\n",
    "    'depths': [1],\n",
    "    'max_len': 128,\n",
    "}\n",
    "\n",
    "# Output directory (use Drive for persistence)\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'experiment_outputs')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Configuration loaded\")\n",
    "print(f\"  PyTorch depths: {PYTORCH_CONFIG['depths']}\")\n",
    "print(f\"  TorchLite depths: {TORCHLITE_CONFIG['depths']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3S_Yf5_0tFZ"
   },
   "source": [
    "## 5. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9pEQ-jd0tFa"
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir='data'):\n",
    "    \"\"\"Load vocabulary, tokenizer, and dataset.\"\"\"\n",
    "    data_dir = os.path.join(PROJECT_DIR, data_dir)\n",
    "    vocab_path = os.path.join(data_dir, 'shared_vocab.txt')\n",
    "    vocab = Vocabulary.load(vocab_path)\n",
    "    tokenizer = NL2BashTokenizer(vocab)\n",
    "\n",
    "    nl_file = os.path.join(data_dir, 'all.nl')\n",
    "    cm_file = os.path.join(data_dir, 'all.cm')\n",
    "    dataset = NL2BashDataset(nl_file, cm_file, tokenizer)\n",
    "\n",
    "    train_dataset, dev_dataset, test_dataset = dataset.split(\n",
    "        train_ratio=10, dev_ratio=1, test_ratio=1, seed=42\n",
    "    )\n",
    "    return vocab, tokenizer, train_dataset, dev_dataset, test_dataset\n",
    "\n",
    "print(\"Loading data...\")\n",
    "vocab, tokenizer, train_dataset, dev_dataset, test_dataset = load_data()\n",
    "\n",
    "print(f\"✓ Data loaded\")\n",
    "print(f\"  Vocab size: {len(vocab)}\")\n",
    "print(f\"  Train examples: {len(train_dataset)}\")\n",
    "print(f\"  Dev examples: {len(dev_dataset)}\")\n",
    "print(f\"  Test examples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_zzUUz40tFa"
   },
   "source": [
    "## 6. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VCJp23F0tFa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_exact_match_pytorch(model, dataset, tokenizer, device, num_samples=100):\n",
    "    \"\"\"Generate commands and compute exact match accuracy (PyTorch).\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = min(num_samples, len(dataset))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(total):\n",
    "            ex = dataset[i]\n",
    "            nl_length = ex['nl_length']\n",
    "            nl_ids = ex['combined_ids'][:nl_length]\n",
    "            nl_tokens = torch.LongTensor([nl_ids]).to(device)\n",
    "\n",
    "            generated = model.generate(\n",
    "                nl_tokens,\n",
    "                start_id=tokenizer.vocab.start_id,\n",
    "                end_id=tokenizer.vocab.end_id,\n",
    "                max_len=64\n",
    "            )\n",
    "\n",
    "            generated_ids = generated[0].cpu().tolist()\n",
    "            generated_text = tokenizer.decode_cm(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "            if generated_text.strip() == ex['cm_text'].strip():\n",
    "                correct += 1\n",
    "\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "print(\"✓ PyTorch helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2f_oHPPb0tFa"
   },
   "outputs": [],
   "source": [
    "def compute_exact_match_lite(model, dataset, tokenizer, num_samples=20):\n",
    "    \"\"\"Generate commands and compute exact match accuracy (TorchLite).\"\"\"\n",
    "    correct = 0\n",
    "    total = min(num_samples, len(dataset))\n",
    "\n",
    "    for i in range(total):\n",
    "        ex = dataset[i]\n",
    "        nl_length = ex['nl_length']\n",
    "        nl_ids = ex['combined_ids'][:nl_length]\n",
    "        nl_tokens = np.array([nl_ids], dtype=np.int64)\n",
    "\n",
    "        generated = model.generate(\n",
    "            nl_tokens,\n",
    "            start_id=tokenizer.vocab.start_id,\n",
    "            end_id=tokenizer.vocab.end_id,\n",
    "            max_len=64\n",
    "        )\n",
    "\n",
    "        generated_ids = generated[0].tolist()\n",
    "        generated_text = tokenizer.decode_cm(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "        if generated_text.strip() == ex['cm_text'].strip():\n",
    "            correct += 1\n",
    "\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "print(\"✓ TorchLite helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlX3jvVs0tFa"
   },
   "outputs": [],
   "source": [
    "def plot_depth_comparison(results, framework_name, config, output_path):\n",
    "    \"\"\"Plot train and dev loss curves for each depth.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    fig.suptitle(f'{framework_name} — Depth Comparison (d_model={config[\"d_model\"]})', fontsize=14)\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, len(results)))\n",
    "\n",
    "    for (depth, data), color in zip(sorted(results.items()), colors):\n",
    "        epochs = list(range(1, len(data['train_losses']) + 1))\n",
    "        label = f'n_layers={depth} ({data[\"n_params\"]:,} params)'\n",
    "\n",
    "        ax1.plot(epochs, data['train_losses'], color=color, label=label, marker='o', markersize=3)\n",
    "        ax2.plot(epochs, data['dev_losses'], color=color, label=label, marker='o', markersize=3)\n",
    "\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.legend(fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_title('Dev Loss')\n",
    "    ax2.legend(fontsize=8)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved plot to {output_path}\")\n",
    "\n",
    "print(\"✓ Plotting functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mM_Mv8F0tFb"
   },
   "outputs": [],
   "source": [
    "def plot_final_bar_chart(results, framework_name, config, output_path):\n",
    "    \"\"\"Bar chart of final train/dev/test loss and exact match per depth.\"\"\"\n",
    "    depths = sorted(results.keys())\n",
    "    train_vals = [results[d]['final_train_loss'] for d in depths]\n",
    "    dev_vals = [results[d]['final_dev_loss'] for d in depths]\n",
    "    test_vals = [results[d]['final_test_loss'] for d in depths]\n",
    "    em_vals = [results[d]['exact_match'] for d in depths]\n",
    "\n",
    "    x = np.arange(len(depths))\n",
    "    width = 0.22\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    fig.suptitle(f'{framework_name} — Final Metrics by Depth (d_model={config[\"d_model\"]})', fontsize=14)\n",
    "\n",
    "    # Loss bar chart\n",
    "    ax1.bar(x - width, train_vals, width, label='Train', color='#2196F3')\n",
    "    ax1.bar(x, dev_vals, width, label='Dev', color='#FF9800')\n",
    "    ax1.bar(x + width, test_vals, width, label='Test', color='#4CAF50')\n",
    "    ax1.set_xlabel('n_layers')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Final Loss')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([str(d) for d in depths])\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Exact match bar chart\n",
    "    bars = ax2.bar(x, [v * 100 for v in em_vals], width * 2, color='#9C27B0')\n",
    "    ax2.set_xlabel('n_layers')\n",
    "    ax2.set_ylabel('Exact Match (%)')\n",
    "    ax2.set_title('Test Exact Match Accuracy')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels([str(d) for d in depths])\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, em_vals):\n",
    "        ax2.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5,\n",
    "                 f'{val:.1%}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved bar chart to {output_path}\")\n",
    "\n",
    "print(\"✓ Bar chart functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktEMQFzB0tFb"
   },
   "outputs": [],
   "source": [
    "def save_results(results, output_path):\n",
    "    \"\"\"Save results dict to JSON.\"\"\"\n",
    "    serializable = {}\n",
    "    for depth, data in results.items():\n",
    "        serializable[str(depth)] = {\n",
    "            'train_losses': [float(x) for x in data['train_losses']],\n",
    "            'dev_losses': [float(x) for x in data['dev_losses']],\n",
    "            'final_train_loss': float(data['final_train_loss']),\n",
    "            'final_dev_loss': float(data['final_dev_loss']),\n",
    "            'final_test_loss': float(data['final_test_loss']),\n",
    "            'exact_match': float(data['exact_match']),\n",
    "            'n_params': int(data['n_params']),\n",
    "        }\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(serializable, f, indent=2)\n",
    "    print(f\"Saved results to {output_path}\")\n",
    "\n",
    "print(\"✓ Results saving functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z_yqIVT0tFb"
   },
   "source": [
    "## 7. Run PyTorch Experiment\n",
    "\n",
    "⚠️ This takes 30-60 minutes with GPU acceleration. You can reduce the `depths` list or `n_epochs` for faster runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0lXXjBb0tFb"
   },
   "outputs": [],
   "source": [
    "# Optional: Reduce config for faster testing\n",
    "# PYTORCH_CONFIG['depths'] = [1]  # Test only depth 1\n",
    "# PYTORCH_CONFIG['n_epochs'] = 2  # Test only 2 epochs\n",
    "\n",
    "print(\"Ready to run PyTorch experiment\")\n",
    "print(f\"Depths: {PYTORCH_CONFIG['depths']}\")\n",
    "print(f\"Epochs: {PYTORCH_CONFIG['n_epochs']}\")\n",
    "print(f\"Batch size: {PYTORCH_CONFIG['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dL0q_F90tFb"
   },
   "outputs": [],
   "source": [
    "# Import PyTorch training functions\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from model.transformer_full import TransformerDecoder\n",
    "from main import compute_masked_loss, train_epoch, evaluate\n",
    "\n",
    "def run_pytorch_experiment(vocab, tokenizer, train_dataset, dev_dataset, test_dataset, config):\n",
    "    \"\"\"Train PyTorch models at each depth and return loss histories + final metrics.\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nPyTorch device: {device}\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for depth in config['depths']:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PyTorch: Training depth={depth}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        model = TransformerDecoder(\n",
    "            vocab_size=len(vocab),\n",
    "            d_model=config['d_model'],\n",
    "            n_heads=config['n_heads'],\n",
    "            n_layers=depth,\n",
    "            d_ff=config['d_ff'],\n",
    "            dropout=config['dropout'],\n",
    "            max_len=config['max_len'],\n",
    "        ).to(device)\n",
    "\n",
    "        n_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"  Parameters: {n_params:,}\")\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "\n",
    "        train_loader = create_pytorch_dataloader(\n",
    "            train_dataset, config['batch_size'], shuffle=True, pad_id=vocab.pad_id\n",
    "        )\n",
    "        dev_loader = create_pytorch_dataloader(\n",
    "            dev_dataset, config['batch_size'], shuffle=False, pad_id=vocab.pad_id\n",
    "        )\n",
    "        test_loader = create_pytorch_dataloader(\n",
    "            test_dataset, config['batch_size'], shuffle=False, pad_id=vocab.pad_id\n",
    "        )\n",
    "\n",
    "        train_losses = []\n",
    "        dev_losses = []\n",
    "\n",
    "        for epoch in range(1, config['n_epochs'] + 1):\n",
    "            train_metrics = train_epoch(model, train_loader, optimizer, device, epoch, log_interval=9999)\n",
    "            dev_metrics = evaluate(model, dev_loader, device)\n",
    "\n",
    "            train_losses.append(train_metrics['loss'])\n",
    "            dev_losses.append(dev_metrics['loss'])\n",
    "\n",
    "            print(f\"  Epoch {epoch:2d}/{config['n_epochs']} | \"\n",
    "                  f\"Train loss: {train_metrics['loss']:.4f} | \"\n",
    "                  f\"Dev loss: {dev_metrics['loss']:.4f} | \"\n",
    "                  f\"Time: {train_metrics['time']:.1f}s\")\n",
    "\n",
    "        # Final evaluation on test set\n",
    "        test_metrics = evaluate(model, test_loader, device)\n",
    "        print(f\"\\n  Test loss: {test_metrics['loss']:.4f}\")\n",
    "\n",
    "        # Exact match accuracy on test set\n",
    "        print(f\"  Computing exact match on test set...\")\n",
    "        exact_match = compute_exact_match_pytorch(model, test_dataset, tokenizer, device, num_samples=100)\n",
    "        print(f\"  Exact match accuracy: {exact_match:.2%}\")\n",
    "\n",
    "        results[depth] = {\n",
    "            'train_losses': train_losses,\n",
    "            'dev_losses': dev_losses,\n",
    "            'final_train_loss': train_losses[-1],\n",
    "            'final_dev_loss': dev_losses[-1],\n",
    "            'final_test_loss': test_metrics['loss'],\n",
    "            'exact_match': exact_match,\n",
    "            'n_params': n_params,\n",
    "        }\n",
    "\n",
    "        print(f\"\\n  >> depth={depth}: \"\n",
    "              f\"train={train_losses[-1]:.4f} | \"\n",
    "              f\"dev={dev_losses[-1]:.4f} | \"\n",
    "              f\"test={test_metrics['loss']:.4f} | \"\n",
    "              f\"exact_match={exact_match:.1%}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"✓ PyTorch experiment function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cdN_5W60tFc"
   },
   "outputs": [],
   "source": [
    "# Run the experiment\n",
    "print(\"=\"*60)\n",
    "print(\"PYTORCH EXPERIMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pytorch_results = run_pytorch_experiment(\n",
    "    vocab, tokenizer, train_dataset, dev_dataset, test_dataset, PYTORCH_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3tYSQQn0tFc"
   },
   "outputs": [],
   "source": [
    "# Save and visualize results\n",
    "save_results(pytorch_results, os.path.join(OUTPUT_DIR, 'pytorch_results.json'))\n",
    "\n",
    "plot_depth_comparison(\n",
    "    pytorch_results, 'PyTorch', PYTORCH_CONFIG,\n",
    "    os.path.join(OUTPUT_DIR, 'pytorch_depth_comparison.png')\n",
    ")\n",
    "\n",
    "plot_final_bar_chart(\n",
    "    pytorch_results, 'PyTorch', PYTORCH_CONFIG,\n",
    "    os.path.join(OUTPUT_DIR, 'pytorch_final_bar_chart.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G8eDIVv0tFc"
   },
   "source": [
    "## 8. Run TorchLite Experiment\n",
    "\n",
    "⚠️ TorchLite uses NumPy-based autograd. Much slower but educational! This takes ~5 minutes for depth=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hQxGJLR0tFc"
   },
   "outputs": [],
   "source": [
    "# Import TorchLite training functions\n",
    "from torchlite.optim import Adam\n",
    "from model.transformer_lite import TransformerDecoderLite\n",
    "from torchlite.tensor import Tensor\n",
    "\n",
    "def compute_masked_loss_lite(logits, targets, loss_mask):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss for TorchLite tensors with masking.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len, vocab_size = logits.shape\n",
    "\n",
    "    # Softmax over vocab dimension\n",
    "    probs = logits.softmax(axis=-1)\n",
    "\n",
    "    # Create one-hot targets\n",
    "    targets_flat = targets.reshape(-1)\n",
    "    one_hot = np.zeros((batch_size * seq_len, vocab_size), dtype=np.float64)\n",
    "    one_hot[np.arange(batch_size * seq_len), targets_flat] = 1.0\n",
    "\n",
    "    # Reshape probs to [batch*seq, vocab]\n",
    "    probs_flat = probs.reshape(batch_size * seq_len, vocab_size)\n",
    "\n",
    "    # Gather: sum(probs * one_hot, axis=-1) gives prob at target index\n",
    "    target_probs = (probs_flat * Tensor(one_hot)).sum(axis=-1)\n",
    "    neg_log_probs = target_probs.log() * Tensor(-1.0)\n",
    "\n",
    "    # Apply mask\n",
    "    mask_flat = Tensor(loss_mask.reshape(-1).astype(np.float64))\n",
    "    masked_losses = neg_log_probs * mask_flat\n",
    "\n",
    "    # Average over masked tokens\n",
    "    n_masked = float(loss_mask.sum()) + 1e-8\n",
    "    loss = masked_losses.sum() * Tensor(1.0 / n_masked)\n",
    "\n",
    "    return loss\n",
    "\n",
    "print(\"✓ TorchLite loss function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNJJgGsM0tFc"
   },
   "outputs": [],
   "source": [
    "def train_epoch_lite(model, dataloader, optimizer, n_batches, epoch):\n",
    "    \"\"\"Train TorchLite model for one epoch.\"\"\"\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        if batch_idx >= n_batches:\n",
    "            break\n",
    "\n",
    "        input_ids = batch['input_ids']\n",
    "        target_ids = batch['target_ids']\n",
    "        loss_mask = batch['loss_mask']\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model.forward(input_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = compute_masked_loss_lite(logits, target_ids, loss_mask)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        n_tokens = float(loss_mask.sum())\n",
    "        total_loss += loss.item() * n_tokens\n",
    "        total_tokens += n_tokens\n",
    "\n",
    "        if (batch_idx + 1) % 5 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            avg_loss = total_loss / total_tokens\n",
    "            print(f\"    Batch {batch_idx + 1}/{n_batches} | Loss: {avg_loss:.4f} | {elapsed:.1f}s\")\n",
    "\n",
    "    avg_loss = total_loss / total_tokens if total_tokens > 0 else float('inf')\n",
    "    return {'loss': avg_loss, 'time': time.time() - start_time}\n",
    "\n",
    "print(\"✓ TorchLite training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eo59O8g40tFd"
   },
   "outputs": [],
   "source": [
    "def evaluate_lite(model, dataloader, n_batches):\n",
    "    \"\"\"Evaluate TorchLite model.\"\"\"\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        if batch_idx >= n_batches:\n",
    "            break\n",
    "\n",
    "        input_ids = batch['input_ids']\n",
    "        target_ids = batch['target_ids']\n",
    "        loss_mask = batch['loss_mask']\n",
    "\n",
    "        logits = model.forward(input_ids)\n",
    "        loss = compute_masked_loss_lite(logits, target_ids, loss_mask)\n",
    "\n",
    "        n_tokens = float(loss_mask.sum())\n",
    "        total_loss += loss.item() * n_tokens\n",
    "        total_tokens += n_tokens\n",
    "\n",
    "    avg_loss = total_loss / total_tokens if total_tokens > 0 else float('inf')\n",
    "    return {'loss': avg_loss}\n",
    "\n",
    "print(\"✓ TorchLite evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pIiIqKG0tFd"
   },
   "outputs": [],
   "source": [
    "def run_torchlite_experiment(vocab, tokenizer, train_dataset, dev_dataset, test_dataset, config):\n",
    "    \"\"\"Train TorchLite models and return loss histories + final metrics.\"\"\"\n",
    "    results = {}\n",
    "    n_train_batches = len(train_dataset) // config['batch_size']\n",
    "    n_dev_batches = max(1, len(dev_dataset) // config['batch_size'])\n",
    "    n_test_batches = max(1, len(test_dataset) // config['batch_size'])\n",
    "\n",
    "    for depth in config['depths']:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"TorchLite: Training depth={depth}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        model = TransformerDecoderLite(\n",
    "            vocab_size=len(vocab),\n",
    "            d_model=config['d_model'],\n",
    "            n_heads=config['n_heads'],\n",
    "            n_layers=depth,\n",
    "            d_ff=config['d_ff'],\n",
    "            max_len=config['max_len'],\n",
    "        )\n",
    "\n",
    "        n_params = sum(p.data.size for p in model.parameters())\n",
    "        print(f\"  Parameters: {n_params:,}\")\n",
    "\n",
    "        optimizer = Adam(model.parameters(), lr=config['lr'])\n",
    "\n",
    "        train_losses = []\n",
    "        dev_losses = []\n",
    "\n",
    "        for epoch in range(1, config['n_epochs'] + 1):\n",
    "            print(f\"\\n  Epoch {epoch}/{config['n_epochs']}\")\n",
    "\n",
    "            train_loader = create_torchlite_dataloader(\n",
    "                train_dataset, config['batch_size'], shuffle=True, pad_id=vocab.pad_id\n",
    "            )\n",
    "            dev_loader = create_torchlite_dataloader(\n",
    "                dev_dataset, config['batch_size'], shuffle=False, pad_id=vocab.pad_id\n",
    "            )\n",
    "\n",
    "            train_metrics = train_epoch_lite(\n",
    "                model, train_loader, optimizer, n_train_batches, epoch\n",
    "            )\n",
    "            dev_metrics = evaluate_lite(model, dev_loader, n_dev_batches)\n",
    "\n",
    "            train_losses.append(train_metrics['loss'])\n",
    "            dev_losses.append(dev_metrics['loss'])\n",
    "\n",
    "            print(f\"  Epoch {epoch} | \"\n",
    "                  f\"Train loss: {train_metrics['loss']:.4f} | \"\n",
    "                  f\"Dev loss: {dev_metrics['loss']:.4f} | \"\n",
    "                  f\"Time: {train_metrics['time']:.1f}s\")\n",
    "\n",
    "        # Final evaluation on test set\n",
    "        test_loader = create_torchlite_dataloader(\n",
    "            test_dataset, config['batch_size'], shuffle=False, pad_id=vocab.pad_id\n",
    "        )\n",
    "        test_metrics = evaluate_lite(model, test_loader, n_test_batches)\n",
    "        print(f\"\\n  Test loss: {test_metrics['loss']:.4f}\")\n",
    "\n",
    "        # Exact match accuracy on test set\n",
    "        print(f\"  Computing exact match on test set...\")\n",
    "        exact_match = compute_exact_match_lite(model, test_dataset, tokenizer, num_samples=20)\n",
    "        print(f\"  Exact match accuracy: {exact_match:.2%}\")\n",
    "\n",
    "        results[depth] = {\n",
    "            'train_losses': train_losses,\n",
    "            'dev_losses': dev_losses,\n",
    "            'final_train_loss': train_losses[-1],\n",
    "            'final_dev_loss': dev_losses[-1],\n",
    "            'final_test_loss': test_metrics['loss'],\n",
    "            'exact_match': exact_match,\n",
    "            'n_params': n_params,\n",
    "        }\n",
    "\n",
    "        print(f\"\\n  >> depth={depth}: \"\n",
    "              f\"train={train_losses[-1]:.4f} | \"\n",
    "              f\"dev={dev_losses[-1]:.4f} | \"\n",
    "              f\"test={test_metrics['loss']:.4f} | \"\n",
    "              f\"exact_match={exact_match:.1%}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"✓ TorchLite experiment function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8a8Q3vM0tFd"
   },
   "outputs": [],
   "source": [
    "# Run the TorchLite experiment\n",
    "print(\"=\"*60)\n",
    "print(\"TORCHLITE EXPERIMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "torchlite_results = run_torchlite_experiment(\n",
    "    vocab, tokenizer, train_dataset, dev_dataset, test_dataset, TORCHLITE_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eJzXfPn0tFd"
   },
   "outputs": [],
   "source": [
    "# Save and visualize TorchLite results\n",
    "save_results(torchlite_results, os.path.join(OUTPUT_DIR, 'torchlite_results.json'))\n",
    "\n",
    "plot_depth_comparison(\n",
    "    torchlite_results, 'TorchLite', TORCHLITE_CONFIG,\n",
    "    os.path.join(OUTPUT_DIR, 'torchlite_depth_comparison.png')\n",
    ")\n",
    "\n",
    "plot_final_bar_chart(\n",
    "    torchlite_results, 'TorchLite', TORCHLITE_CONFIG,\n",
    "    os.path.join(OUTPUT_DIR, 'torchlite_final_bar_chart.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OJ0WKR80tFd"
   },
   "source": [
    "## 9. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJlpUMOF0tFe"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nResults saved to: {OUTPUT_DIR}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    path = os.path.join(OUTPUT_DIR, f)\n",
    "    if os.path.isfile(path):\n",
    "        size = os.path.getsize(path) / 1024\n",
    "        print(f\"  - {f} ({size:.1f} KB)\")\n",
    "\n",
    "print(\"\\n✓ All experiments completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bNm0H1K0tFe"
   },
   "outputs": [],
   "source": [
    "# Optional: Copy results to Google Drive\n",
    "# import shutil\n",
    "# drive_dir = '/content/drive/MyDrive/nl2bash_results'\n",
    "# shutil.copytree(OUTPUT_DIR, drive_dir, dirs_exist_ok=True)\n",
    "# print(f\"Results copied to Drive: {drive_dir}\")\n",
    "\n",
    "print(\"To save results to Drive, uncomment the cell above and update the path.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qZWC_MgV0tFV",
    "8nVJH_cK0tFX",
    "p3S_Yf5_0tFZ",
    "2z_yqIVT0tFb"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
