{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZWC_MgV0tFV"
   },
   "source": [
    "# WikiText-2 Depth Experiment - Colab Notebook (PyTorch)\n",
    "\n",
    "This notebook runs PyTorch depth experiments for the project in `03-wikitext2`.\n",
    "\n",
    "**What this notebook now does:**\n",
    "- installs PyTorch dependencies in Colab\n",
    "- clones the project directly from GitHub (no ZIP upload)\n",
    "- verifies required project/data files\n",
    "- runs and saves PyTorch experiment results\n",
    "\n",
    "**Run time estimate:**\n",
    "- PyTorch (all depths): ~30-60 min on GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H5_2Oq40tFW"
   },
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kD_8R8h80tFW"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q matplotlib numpy kagglehub\n",
    "\n",
    "print(\"\u2713 Dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_C_K4Kz0tFX"
   },
   "outputs": [],
   "source": [
    "# Optional: mount Google Drive for persistent outputs\n",
    "MOUNT_DRIVE = False\n",
    "\n",
    "if MOUNT_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"\u2713 Google Drive mounted\")\n",
    "else:\n",
    "    print(\"Drive mount skipped (set MOUNT_DRIVE=True to enable)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SX7cX2gP0tFX"
   },
   "outputs": [],
   "source": [
    "# Clone project from GitHub (no manual ZIP upload required)\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = 'https://github.com/ng3gn/ground-up-vla.git'\n",
    "REPO_BRANCH = 'main'\n",
    "PROJECT_SUBDIR = '03-wikitext2'  # set to '' if this project is at repo root\n",
    "CHECKOUT_DIR = '/content/ground-up-vla'\n",
    "\n",
    "if os.path.exists(CHECKOUT_DIR):\n",
    "    shutil.rmtree(CHECKOUT_DIR)\n",
    "\n",
    "subprocess.run(['git', 'clone', '--depth', '1', '--branch', REPO_BRANCH, REPO_URL, CHECKOUT_DIR], check=True)\n",
    "PROJECT_DIR = os.path.join(CHECKOUT_DIR, PROJECT_SUBDIR) if PROJECT_SUBDIR else CHECKOUT_DIR\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(f\"\u2713 Repo cloned to: {CHECKOUT_DIR}\")\n",
    "print(f\"\u2713 Working directory: {PROJECT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nVJH_cK0tFX"
   },
   "source": [
    "## 2. Verify Project Checkout\n",
    "\n",
    "This replaces manual Drive/ZIP copy steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vLDdXRl0tFY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "required_files = [\n",
    "    'vocab.py',\n",
    "    'tokenizer.py',\n",
    "    'dataset.py',\n",
    "    'main.py',\n",
    "    'model/transformer_full.py',\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for f in required_files:\n",
    "    path = os.path.join(PROJECT_DIR, f)\n",
    "    if os.path.exists(path):\n",
    "        print(f\"\u2713 {f}\")\n",
    "    else:\n",
    "        print(f\"\u2717 {f}\")\n",
    "        missing.append(f)\n",
    "\n",
    "if missing:\n",
    "    raise FileNotFoundError(f\"Missing required project files: {missing}\")\n",
    "\n",
    "print(\"\n",
    "\u2713 Project files verified\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QX3j7yAj0tFY"
   },
   "source": [
    "## 3. Download WikiText-2 from Kaggle Hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f_8XT1D0tFY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Set this if you know the exact Kaggle dataset handle. Leave None to auto-try common handles.\n",
    "KAGGLE_WIKITEXT2_HANDLE = None\n",
    "CANDIDATE_HANDLES = [\n",
    "    'jboysen/wikitext2',\n",
    "    'jboysen/wikitext-2',\n",
    "    'mrityunjaybiswas/wikitext2',\n",
    "    'mrityunjaybiswas/wikitext-2',\n",
    "]\n",
    "\n",
    "handles_to_try = [KAGGLE_WIKITEXT2_HANDLE] if KAGGLE_WIKITEXT2_HANDLE else CANDIDATE_HANDLES\n",
    "last_err = None\n",
    "raw_download_dir = None\n",
    "\n",
    "for handle in handles_to_try:\n",
    "    try:\n",
    "        print(f\"Trying Kaggle handle: {handle}\")\n",
    "        raw_download_dir = kagglehub.dataset_download(handle)\n",
    "        print(f\"\u2713 Downloaded with handle: {handle}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "        print(f\"\u2717 Failed: {handle} -> {e}\")\n",
    "\n",
    "if raw_download_dir is None:\n",
    "    raise RuntimeError(\n",
    "        \"Could not download WikiText-2 via kagglehub. \"\n",
    "        \"Set KAGGLE_WIKITEXT2_HANDLE to your dataset handle and rerun this cell.\n",
    "\"\n",
    "        f\"Last error: {last_err}\"\n",
    "    )\n",
    "\n",
    "# Find the directory that actually contains WikiText-2 text files.\n",
    "required = {'wiki.train.tokens', 'wiki.valid.tokens', 'wiki.test.tokens'}\n",
    "WIKITEXT2_DIR = None\n",
    "for root, _, files in os.walk(raw_download_dir):\n",
    "    if required.issubset(set(files)):\n",
    "        WIKITEXT2_DIR = root\n",
    "        break\n",
    "\n",
    "if WIKITEXT2_DIR is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Downloaded dataset did not contain expected files: \"\n",
    "        \"wiki.train.tokens, wiki.valid.tokens, wiki.test.tokens\"\n",
    "    )\n",
    "\n",
    "print(f\"\u2713 WikiText-2 directory: {WIKITEXT2_DIR}\")\n",
    "for name in sorted(required):\n",
    "    p = os.path.join(WIKITEXT2_DIR, name)\n",
    "    size_mb = os.path.getsize(p) / 1024 / 1024\n",
    "    print(f\"  - {name} ({size_mb:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz-7a3c30tFY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yy3SQK_0tFZ"
   },
   "source": [
    "## 4. Import Modules & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKkPFT9x0tFZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add project directory to path\n",
    "sys.path.insert(0, PROJECT_DIR)\n",
    "\n",
    "from vocab import Vocabulary\n",
    "from tokenizer import NL2BashTokenizer\n",
    "from dataset import NL2BashDataset, create_pytorch_dataloader\n",
    "\n",
    "print(\"\u2713 All modules imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6C0w-sZ0tFZ"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "PYTORCH_CONFIG = {\n",
    "    'd_model': 128,\n",
    "    'n_heads': 1,\n",
    "    'd_ff': 512,\n",
    "    'batch_size': 16,\n",
    "    'lr': 0.0001,\n",
    "    'n_epochs': 20,\n",
    "    'depths': [1, 2, 4, 8, 16],\n",
    "    'dropout': 0.0,\n",
    "    'max_len': 128,\n",
    "}\n",
    "\n",
    "# Output directory (use Drive path if mounted)\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'experiment_outputs')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"\u2713 Configuration loaded\")\n",
    "print(f\"  PyTorch depths: {PYTORCH_CONFIG['depths']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3S_Yf5_0tFZ"
   },
   "source": [
    "## 5. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9pEQ-jd0tFa"
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir='data'):\n",
    "    \"\"\"Load vocabulary, tokenizer, and dataset (legacy NL2Bash path).\"\"\"\n",
    "    data_dir = os.path.join(PROJECT_DIR, data_dir)\n",
    "    vocab_path = os.path.join(data_dir, 'shared_vocab.txt')\n",
    "    vocab = Vocabulary.load(vocab_path)\n",
    "    tokenizer = NL2BashTokenizer(vocab)\n",
    "\n",
    "    nl_file = os.path.join(data_dir, 'all.nl')\n",
    "    cm_file = os.path.join(data_dir, 'all.cm')\n",
    "    dataset = NL2BashDataset(nl_file, cm_file, tokenizer)\n",
    "\n",
    "    train_dataset, dev_dataset, test_dataset = dataset.split(\n",
    "        train_ratio=10, dev_ratio=1, test_ratio=1, seed=42\n",
    "    )\n",
    "    return vocab, tokenizer, train_dataset, dev_dataset, test_dataset\n",
    "\n",
    "print(f\"WikiText-2 files are available at: {WIKITEXT2_DIR}\")\n",
    "print(\"If your branch now uses WikiText-2 loaders, replace this cell with that loader logic.\")\n",
    "print(\"For now, the code below still uses the legacy NL2Bash loader.\")\n",
    "\n",
    "print(\"Loading data...\")\n",
    "vocab, tokenizer, train_dataset, dev_dataset, test_dataset = load_data()\n",
    "\n",
    "print(f\"\u2713 Data loaded\")\n",
    "print(f\"  Vocab size: {len(vocab)}\")\n",
    "print(f\"  Train examples: {len(train_dataset)}\")\n",
    "print(f\"  Dev examples: {len(dev_dataset)}\")\n",
    "print(f\"  Test examples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_zzUUz40tFa"
   },
   "source": [
    "## 6. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VCJp23F0tFa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_exact_match_pytorch(model, dataset, tokenizer, device, num_samples=100):\n",
    "    \"\"\"Generate commands and compute exact match accuracy (PyTorch).\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = min(num_samples, len(dataset))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(total):\n",
    "            ex = dataset[i]\n",
    "            nl_length = ex['nl_length']\n",
    "            nl_ids = ex['combined_ids'][:nl_length]\n",
    "            nl_tokens = torch.LongTensor([nl_ids]).to(device)\n",
    "\n",
    "            generated = model.generate(\n",
    "                nl_tokens,\n",
    "                start_id=tokenizer.vocab.start_id,\n",
    "                end_id=tokenizer.vocab.end_id,\n",
    "                max_len=64\n",
    "            )\n",
    "\n",
    "            generated_ids = generated[0].cpu().tolist()\n",
    "            generated_text = tokenizer.decode_cm(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "            if generated_text.strip() == ex['cm_text'].strip():\n",
    "                correct += 1\n",
    "\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "print(\"\u2713 PyTorch helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MlX3jvVs0tFa"
   },
   "outputs": [],
   "source": [
    "def plot_depth_comparison(results, framework_name, config, output_path):\n",
    "    \"\"\"Plot train and dev loss curves for each depth.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    fig.suptitle(f'{framework_name} \u2014 Depth Comparison (d_model={config[\"d_model\"]})', fontsize=14)\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, len(results)))\n",
    "\n",
    "    for (depth, data), color in zip(sorted(results.items()), colors):\n",
    "        epochs = list(range(1, len(data['train_losses']) + 1))\n",
    "        label = f'n_layers={depth} ({data[\"n_params\"]:,} params)'\n",
    "\n",
    "        ax1.plot(epochs, data['train_losses'], color=color, label=label, marker='o', markersize=3)\n",
    "        ax2.plot(epochs, data['dev_losses'], color=color, label=label, marker='o', markersize=3)\n",
    "\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training Loss')\n",
    "    ax1.legend(fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_title('Dev Loss')\n",
    "    ax2.legend(fontsize=8)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved plot to {output_path}\")\n",
    "\n",
    "print(\"\u2713 Plotting functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mM_Mv8F0tFb"
   },
   "outputs": [],
   "source": [
    "def plot_final_bar_chart(results, framework_name, config, output_path):\n",
    "    \"\"\"Bar chart of final train/dev/test loss and exact match per depth.\"\"\"\n",
    "    depths = sorted(results.keys())\n",
    "    train_vals = [results[d]['final_train_loss'] for d in depths]\n",
    "    dev_vals = [results[d]['final_dev_loss'] for d in depths]\n",
    "    test_vals = [results[d]['final_test_loss'] for d in depths]\n",
    "    em_vals = [results[d]['exact_match'] for d in depths]\n",
    "\n",
    "    x = np.arange(len(depths))\n",
    "    width = 0.22\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    fig.suptitle(f'{framework_name} \u2014 Final Metrics by Depth (d_model={config[\"d_model\"]})', fontsize=14)\n",
    "\n",
    "    # Loss bar chart\n",
    "    ax1.bar(x - width, train_vals, width, label='Train', color='#2196F3')\n",
    "    ax1.bar(x, dev_vals, width, label='Dev', color='#FF9800')\n",
    "    ax1.bar(x + width, test_vals, width, label='Test', color='#4CAF50')\n",
    "    ax1.set_xlabel('n_layers')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Final Loss')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([str(d) for d in depths])\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "    # Exact match bar chart\n",
    "    bars = ax2.bar(x, [v * 100 for v in em_vals], width * 2, color='#9C27B0')\n",
    "    ax2.set_xlabel('n_layers')\n",
    "    ax2.set_ylabel('Exact Match (%)')\n",
    "    ax2.set_title('Test Exact Match Accuracy')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels([str(d) for d in depths])\n",
    "    ax2.grid(True, alpha=0.3, axis='y')\n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, em_vals):\n",
    "        ax2.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.5,\n",
    "                 f'{val:.1%}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Saved bar chart to {output_path}\")\n",
    "\n",
    "print(\"\u2713 Bar chart functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktEMQFzB0tFb"
   },
   "outputs": [],
   "source": [
    "def save_results(results, output_path):\n",
    "    \"\"\"Save results dict to JSON.\"\"\"\n",
    "    serializable = {}\n",
    "    for depth, data in results.items():\n",
    "        serializable[str(depth)] = {\n",
    "            'train_losses': [float(x) for x in data['train_losses']],\n",
    "            'dev_losses': [float(x) for x in data['dev_losses']],\n",
    "            'final_train_loss': float(data['final_train_loss']),\n",
    "            'final_dev_loss': float(data['final_dev_loss']),\n",
    "            'final_test_loss': float(data['final_test_loss']),\n",
    "            'exact_match': float(data['exact_match']),\n",
    "            'n_params': int(data['n_params']),\n",
    "        }\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(serializable, f, indent=2)\n",
    "    print(f\"Saved results to {output_path}\")\n",
    "\n",
    "print(\"\u2713 Results saving functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z_yqIVT0tFb"
   },
   "source": [
    "## 7. Run PyTorch Experiment\n",
    "\n",
    "\u26a0\ufe0f This takes 30-60 minutes with GPU acceleration. You can reduce the `depths` list or `n_epochs` for faster runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0lXXjBb0tFb"
   },
   "outputs": [],
   "source": [
    "# Optional: Reduce config for faster testing\n",
    "# PYTORCH_CONFIG['depths'] = [1]  # Test only depth 1\n",
    "# PYTORCH_CONFIG['n_epochs'] = 2  # Test only 2 epochs\n",
    "\n",
    "print(\"Ready to run PyTorch experiment\")\n",
    "print(f\"Depths: {PYTORCH_CONFIG['depths']}\")\n",
    "print(f\"Epochs: {PYTORCH_CONFIG['n_epochs']}\")\n",
    "print(f\"Batch size: {PYTORCH_CONFIG['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dL0q_F90tFb"
   },
   "outputs": [],
   "source": [
    "# Import PyTorch training functions\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from model.transformer_full import TransformerDecoder\n",
    "from main import compute_masked_loss, train_epoch, evaluate\n",
    "\n",
    "def run_pytorch_experiment(vocab, tokenizer, train_dataset, dev_dataset, test_dataset, config):\n",
    "    \"\"\"Train PyTorch models at each depth and return loss histories + final metrics.\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\nPyTorch device: {device}\")\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for depth in config['depths']:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PyTorch: Training depth={depth}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        model = TransformerDecoder(\n",
    "            vocab_size=len(vocab),\n",
    "            d_model=config['d_model'],\n",
    "            n_heads=config['n_heads'],\n",
    "            n_layers=depth,\n",
    "            d_ff=config['d_ff'],\n",
    "            dropout=config['dropout'],\n",
    "            max_len=config['max_len'],\n",
    "        ).to(device)\n",
    "\n",
    "        n_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f\"  Parameters: {n_params:,}\")\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "\n",
    "        train_loader = create_pytorch_dataloader(\n",
    "            train_dataset, config['batch_size'], shuffle=True, pad_id=vocab.pad_id\n",
    "        )\n",
    "        dev_loader = create_pytorch_dataloader(\n",
    "            dev_dataset, config['batch_size'], shuffle=False, pad_id=vocab.pad_id\n",
    "        )\n",
    "        test_loader = create_pytorch_dataloader(\n",
    "            test_dataset, config['batch_size'], shuffle=False, pad_id=vocab.pad_id\n",
    "        )\n",
    "\n",
    "        train_losses = []\n",
    "        dev_losses = []\n",
    "\n",
    "        for epoch in range(1, config['n_epochs'] + 1):\n",
    "            train_metrics = train_epoch(model, train_loader, optimizer, device, epoch, log_interval=9999)\n",
    "            dev_metrics = evaluate(model, dev_loader, device)\n",
    "\n",
    "            train_losses.append(train_metrics['loss'])\n",
    "            dev_losses.append(dev_metrics['loss'])\n",
    "\n",
    "            print(f\"  Epoch {epoch:2d}/{config['n_epochs']} | \"\n",
    "                  f\"Train loss: {train_metrics['loss']:.4f} | \"\n",
    "                  f\"Dev loss: {dev_metrics['loss']:.4f} | \"\n",
    "                  f\"Time: {train_metrics['time']:.1f}s\")\n",
    "\n",
    "        # Final evaluation on test set\n",
    "        test_metrics = evaluate(model, test_loader, device)\n",
    "        print(f\"\\n  Test loss: {test_metrics['loss']:.4f}\")\n",
    "\n",
    "        # Exact match accuracy on test set\n",
    "        print(f\"  Computing exact match on test set...\")\n",
    "        exact_match = compute_exact_match_pytorch(model, test_dataset, tokenizer, device, num_samples=100)\n",
    "        print(f\"  Exact match accuracy: {exact_match:.2%}\")\n",
    "\n",
    "        results[depth] = {\n",
    "            'train_losses': train_losses,\n",
    "            'dev_losses': dev_losses,\n",
    "            'final_train_loss': train_losses[-1],\n",
    "            'final_dev_loss': dev_losses[-1],\n",
    "            'final_test_loss': test_metrics['loss'],\n",
    "            'exact_match': exact_match,\n",
    "            'n_params': n_params,\n",
    "        }\n",
    "\n",
    "        print(f\"\\n  >> depth={depth}: \"\n",
    "              f\"train={train_losses[-1]:.4f} | \"\n",
    "              f\"dev={dev_losses[-1]:.4f} | \"\n",
    "              f\"test={test_metrics['loss']:.4f} | \"\n",
    "              f\"exact_match={exact_match:.1%}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "print(\"\u2713 PyTorch experiment function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cdN_5W60tFc"
   },
   "outputs": [],
   "source": [
    "# Run the experiment\n",
    "print(\"=\"*60)\n",
    "print(\"PYTORCH EXPERIMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pytorch_results = run_pytorch_experiment(\n",
    "    vocab, tokenizer, train_dataset, dev_dataset, test_dataset, PYTORCH_CONFIG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3tYSQQn0tFc"
   },
   "outputs": [],
   "source": [
    "# Save and visualize results\n",
    "save_results(pytorch_results, os.path.join(OUTPUT_DIR, 'pytorch_results.json'))\n",
    "\n",
    "plot_depth_comparison(\n",
    "    pytorch_results, 'PyTorch', PYTORCH_CONFIG,\n",
    "    os.path.join(OUTPUT_DIR, 'pytorch_depth_comparison.png')\n",
    ")\n",
    "\n",
    "plot_final_bar_chart(\n",
    "    pytorch_results, 'PyTorch', PYTORCH_CONFIG,\n",
    "    os.path.join(OUTPUT_DIR, 'pytorch_final_bar_chart.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OJ0WKR80tFd"
   },
   "source": [
    "## 8. Summary & Next Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJlpUMOF0tFe"
   },
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('EXPERIMENT COMPLETE')\n",
    "print('='*60)\n",
    "print(f'\\nResults saved to: {OUTPUT_DIR}')\n",
    "print('\\nGenerated files:')\n",
    "for f in os.listdir(OUTPUT_DIR):\n",
    "    path = os.path.join(OUTPUT_DIR, f)\n",
    "    if os.path.isfile(path):\n",
    "        size = os.path.getsize(path) / 1024\n",
    "        print(f'  - {f} ({size:.1f} KB)')\n",
    "\n",
    "print('\\n\u2713 PyTorch experiment completed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bNm0H1K0tFe"
   },
   "outputs": [],
   "source": [
    "# Optional: copy results to Google Drive (if mounted)\n",
    "# import shutil\n",
    "# drive_dir = '/content/drive/MyDrive/wikitext2_results'\n",
    "# shutil.copytree(OUTPUT_DIR, drive_dir, dirs_exist_ok=True)\n",
    "# print(f\"Results copied to Drive: {drive_dir}\")\n",
    "\n",
    "print(\"To copy results to Drive, mount Drive and uncomment this cell.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qZWC_MgV0tFV",
    "8nVJH_cK0tFX",
    "p3S_Yf5_0tFZ",
    "2z_yqIVT0tFb"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}