{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiText-2 Depth Experiment - Colab Notebook (PyTorch)\n",
    "\n",
    "This notebook runs decoder-only Transformer depth experiments on WikiText-2.\n",
    "\n",
    "What this notebook does:\n",
    "- installs dependencies\n",
    "- clones the project directly from GitHub (no ZIP upload)\n",
    "- downloads WikiText-2 via `kagglehub`\n",
    "- builds a simple language modeling dataset\n",
    "- trains PyTorch models at multiple depths and compares metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q matplotlib numpy kagglehub\n",
    "\n",
    "print('Dependencies installed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: mount Google Drive for persistent outputs\n",
    "MOUNT_DRIVE = False\n",
    "\n",
    "if MOUNT_DRIVE:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Google Drive mounted')\n",
    "else:\n",
    "    print('Drive mount skipped (set MOUNT_DRIVE=True to enable)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone project from GitHub (no manual ZIP upload required)\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "REPO_URL = 'https://github.com/ng3gn/ground-up-vla.git'\n",
    "REPO_BRANCH = 'main'\n",
    "PROJECT_SUBDIR = '03-wikitext2'\n",
    "CHECKOUT_DIR = '/content/ground-up-vla'\n",
    "\n",
    "if os.path.exists(CHECKOUT_DIR):\n",
    "    shutil.rmtree(CHECKOUT_DIR)\n",
    "\n",
    "subprocess.run(['git', 'clone', '--depth', '1', '--branch', REPO_BRANCH, REPO_URL, CHECKOUT_DIR], check=True)\n",
    "PROJECT_DIR = os.path.join(CHECKOUT_DIR, PROJECT_SUBDIR)\n",
    "os.chdir(PROJECT_DIR)\n",
    "\n",
    "print(f'Repo cloned to: {CHECKOUT_DIR}')\n",
    "print(f'Working directory: {PROJECT_DIR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download WikiText-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "WIKITEXT2_DIR = kagglehub.dataset_download('vivekmettu/wikitext2-data')\n",
    "\n",
    "required = {'wiki.train.tokens', 'wiki.valid.tokens', 'wiki.test.tokens'}\n",
    "if not required.issubset(set(os.listdir(WIKITEXT2_DIR))):\n",
    "    # Some Kaggle datasets place files in a nested subfolder.\n",
    "    found = None\n",
    "    for root, _, files in os.walk(WIKITEXT2_DIR):\n",
    "        if required.issubset(set(files)):\n",
    "            found = root\n",
    "            break\n",
    "    if found is None:\n",
    "        raise FileNotFoundError('Could not find wiki.train/valid/test.tokens in downloaded dataset')\n",
    "    WIKITEXT2_DIR = found\n",
    "\n",
    "print('Path to dataset files:', WIKITEXT2_DIR)\n",
    "for fname in sorted(required):\n",
    "    path = os.path.join(WIKITEXT2_DIR, fname)\n",
    "    size_mb = os.path.getsize(path) / 1024 / 1024\n",
    "    print(f'  - {fname} ({size_mb:.2f} MB)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Imports and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Reuse project model implementation\n",
    "import sys\n",
    "sys.path.insert(0, PROJECT_DIR)\n",
    "from model.transformer_full import TransformerDecoder\n",
    "\n",
    "print('Modules imported')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'd_model': 256,\n",
    "    'n_heads': 4,\n",
    "    'd_ff': 1024,\n",
    "    'dropout': 0.1,\n",
    "    'max_len': 128,\n",
    "    'batch_size': 32,\n",
    "    'lr': 3e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'n_epochs': 8,\n",
    "    'depths': [1, 2, 4, 8],\n",
    "    'max_vocab_size': 20000,\n",
    "    'min_freq': 2,\n",
    "    'max_train_tokens': 1200000,\n",
    "    'grad_clip': 1.0,\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, 'experiment_outputs_wikitext2')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print('Configuration loaded')\n",
    "print('Depths:', CONFIG['depths'])\n",
    "print('Output dir:', OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build WikiText-2 Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wikitext_split(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        lines = [line.strip() for line in f]\n",
    "    return [line for line in lines if line]\n",
    "\n",
    "\n",
    "def build_vocab(train_lines, max_vocab_size=20000, min_freq=2):\n",
    "    counter = Counter()\n",
    "    for line in train_lines:\n",
    "        counter.update(line.split())\n",
    "\n",
    "    specials = ['<pad>', '<unk>', '<eos>']\n",
    "    tokens = [tok for tok, freq in counter.most_common() if freq >= min_freq]\n",
    "    tokens = tokens[: max_vocab_size - len(specials)]\n",
    "    itos = specials + tokens\n",
    "    stoi = {tok: i for i, tok in enumerate(itos)}\n",
    "    return stoi, itos\n",
    "\n",
    "\n",
    "def encode_lines(lines, stoi):\n",
    "    unk_id = stoi['<unk>']\n",
    "    eos_id = stoi['<eos>']\n",
    "    ids = []\n",
    "    for line in lines:\n",
    "        ids.extend(stoi.get(tok, unk_id) for tok in line.split())\n",
    "        ids.append(eos_id)\n",
    "    return ids\n",
    "\n",
    "\n",
    "def make_lm_blocks(token_ids, seq_len):\n",
    "    n_blocks = (len(token_ids) - 1) // seq_len\n",
    "    if n_blocks <= 0:\n",
    "        raise ValueError('Not enough tokens to create at least one block')\n",
    "\n",
    "    trim = n_blocks * seq_len + 1\n",
    "    arr = torch.tensor(token_ids[:trim], dtype=torch.long)\n",
    "    x = arr[:-1].view(n_blocks, seq_len)\n",
    "    y = arr[1:].view(n_blocks, seq_len)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "train_lines = read_wikitext_split(os.path.join(WIKITEXT2_DIR, 'wiki.train.tokens'))\n",
    "valid_lines = read_wikitext_split(os.path.join(WIKITEXT2_DIR, 'wiki.valid.tokens'))\n",
    "test_lines = read_wikitext_split(os.path.join(WIKITEXT2_DIR, 'wiki.test.tokens'))\n",
    "\n",
    "stoi, itos = build_vocab(\n",
    "    train_lines,\n",
    "    max_vocab_size=CONFIG['max_vocab_size'],\n",
    "    min_freq=CONFIG['min_freq'],\n",
    ")\n",
    "\n",
    "train_ids = encode_lines(train_lines, stoi)\n",
    "valid_ids = encode_lines(valid_lines, stoi)\n",
    "test_ids = encode_lines(test_lines, stoi)\n",
    "\n",
    "if CONFIG['max_train_tokens'] is not None:\n",
    "    train_ids = train_ids[:CONFIG['max_train_tokens']]\n",
    "\n",
    "train_x, train_y = make_lm_blocks(train_ids, CONFIG['max_len'])\n",
    "valid_x, valid_y = make_lm_blocks(valid_ids, CONFIG['max_len'])\n",
    "test_x, test_y = make_lm_blocks(test_ids, CONFIG['max_len'])\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(train_x, train_y), batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "valid_loader = DataLoader(TensorDataset(valid_x, valid_y), batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(test_x, test_y), batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print('WikiText-2 prepared')\n",
    "print('Vocab size:', len(itos))\n",
    "print('Train blocks:', len(train_x))\n",
    "print('Valid blocks:', len(valid_x))\n",
    "print('Test blocks:', len(test_x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lm(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1), reduction='sum')\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total_tokens += y.numel()\n",
    "\n",
    "    avg_loss = total_loss / max(total_tokens, 1)\n",
    "    ppl = float(np.exp(avg_loss))\n",
    "    acc = total_correct / max(total_tokens, 1)\n",
    "\n",
    "    return {'loss': avg_loss, 'perplexity': ppl, 'token_acc': acc}\n",
    "\n",
    "\n",
    "def train_epoch_lm(model, dataloader, optimizer, device, grad_clip=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    t0 = time.time()\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), y.view(-1), reduction='mean')\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y.numel()\n",
    "        total_tokens += y.numel()\n",
    "\n",
    "    avg_loss = total_loss / max(total_tokens, 1)\n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'perplexity': float(np.exp(avg_loss)),\n",
    "        'time': time.time() - t0,\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_text(model, prompt, stoi, itos, device, max_len_ctx=128, max_new_tokens=40, temperature=1.0):\n",
    "    model.eval()\n",
    "    unk_id = stoi['<unk>']\n",
    "    eos_id = stoi['<eos>']\n",
    "\n",
    "    ids = [stoi.get(tok, unk_id) for tok in prompt.split()]\n",
    "    if not ids:\n",
    "        ids = [eos_id]\n",
    "\n",
    "    x = torch.tensor([ids], dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            if x.size(1) > max_len_ctx:\n",
    "                x = x[:, -max_len_ctx:]\n",
    "\n",
    "            logits = model(x)\n",
    "            next_logits = logits[:, -1, :] / max(temperature, 1e-5)\n",
    "            probs = torch.softmax(next_logits, dim=-1)\n",
    "            next_id = torch.multinomial(probs, num_samples=1)\n",
    "            x = torch.cat([x, next_id], dim=1)\n",
    "\n",
    "            if next_id.item() == eos_id:\n",
    "                break\n",
    "\n",
    "    out_ids = x[0].tolist()\n",
    "    out_toks = [itos[i] if 0 <= i < len(itos) else '<unk>' for i in out_ids]\n",
    "    return ' '.join(tok for tok in out_toks if tok != '<eos>')\n",
    "\n",
    "\n",
    "print('Helper functions defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_depth_comparison(results, config, output_path):\n",
    "    depths = sorted(results.keys())\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig.suptitle(f\"PyTorch WikiText-2 Depth Comparison (d_model={config['d_model']})\", fontsize=14)\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 0.9, len(depths)))\n",
    "\n",
    "    for depth, color in zip(depths, colors):\n",
    "        data = results[depth]\n",
    "        epochs = list(range(1, len(data['train_losses']) + 1))\n",
    "        label = f\"layers={depth} ({data['n_params']:,} params)\"\n",
    "\n",
    "        axes[0].plot(epochs, data['train_losses'], color=color, marker='o', markersize=3, label=label)\n",
    "        axes[1].plot(epochs, data['valid_losses'], color=color, marker='o', markersize=3, label=label)\n",
    "        axes[2].plot(epochs, data['valid_ppls'], color=color, marker='o', markersize=3, label=label)\n",
    "\n",
    "    axes[0].set_title('Train Loss')\n",
    "    axes[1].set_title('Valid Loss')\n",
    "    axes[2].set_title('Valid Perplexity')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[2].set_ylabel('Perplexity')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('Saved plot to', output_path)\n",
    "\n",
    "\n",
    "print('Plotting function defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_final_metrics(results, output_path):\n",
    "    depths = sorted(results.keys())\n",
    "\n",
    "    test_losses = [results[d]['test_loss'] for d in depths]\n",
    "    test_ppls = [results[d]['test_perplexity'] for d in depths]\n",
    "    test_accs = [results[d]['test_token_acc'] for d in depths]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    axes[0].bar([str(d) for d in depths], test_losses)\n",
    "    axes[0].set_title('Test Loss by Depth')\n",
    "    axes[0].set_xlabel('Depth')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "\n",
    "    axes[1].bar([str(d) for d in depths], test_ppls)\n",
    "    axes[1].set_title('Test Perplexity by Depth')\n",
    "    axes[1].set_xlabel('Depth')\n",
    "    axes[1].set_ylabel('Perplexity')\n",
    "\n",
    "    axes[2].bar([str(d) for d in depths], test_accs)\n",
    "    axes[2].set_title('Test Token Accuracy by Depth')\n",
    "    axes[2].set_xlabel('Depth')\n",
    "    axes[2].set_ylabel('Accuracy')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print('Saved plot to', output_path)\n",
    "\n",
    "\n",
    "print('Final metric plotting function defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, output_path):\n",
    "    serializable = {}\n",
    "    for depth, data in results.items():\n",
    "        serializable[str(depth)] = {}\n",
    "        for k, v in data.items():\n",
    "            if isinstance(v, (np.floating, np.integer)):\n",
    "                serializable[str(depth)][k] = float(v)\n",
    "            else:\n",
    "                serializable[str(depth)][k] = v\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(serializable, f, indent=2)\n",
    "\n",
    "    print('Saved results to', output_path)\n",
    "\n",
    "\n",
    "print('Result saver defined')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run PyTorch Experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: reduce runtime for quick checks\n",
    "# CONFIG['depths'] = [1, 2]\n",
    "# CONFIG['n_epochs'] = 2\n",
    "# CONFIG['max_train_tokens'] = 300000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pytorch_experiment(config):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for depth in config['depths']:\n",
    "        print('\\n' + '=' * 60)\n",
    "        print(f'Training depth={depth}')\n",
    "        print('=' * 60)\n",
    "\n",
    "        model = TransformerDecoder(\n",
    "            vocab_size=len(itos),\n",
    "            d_model=config['d_model'],\n",
    "            n_heads=config['n_heads'],\n",
    "            n_layers=depth,\n",
    "            d_ff=config['d_ff'],\n",
    "            dropout=config['dropout'],\n",
    "            max_len=config['max_len'],\n",
    "        ).to(device)\n",
    "\n",
    "        n_params = sum(p.numel() for p in model.parameters())\n",
    "        print(f'Parameters: {n_params:,}')\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        valid_ppls = []\n",
    "\n",
    "        for epoch in range(1, config['n_epochs'] + 1):\n",
    "            train_metrics = train_epoch_lm(\n",
    "                model,\n",
    "                train_loader,\n",
    "                optimizer,\n",
    "                device,\n",
    "                grad_clip=config['grad_clip'],\n",
    "            )\n",
    "            valid_metrics = evaluate_lm(model, valid_loader, device)\n",
    "\n",
    "            train_losses.append(train_metrics['loss'])\n",
    "            valid_losses.append(valid_metrics['loss'])\n",
    "            valid_ppls.append(valid_metrics['perplexity'])\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch:2d}/{config['n_epochs']} | \"\n",
    "                f\"train loss {train_metrics['loss']:.4f} | \"\n",
    "                f\"valid loss {valid_metrics['loss']:.4f} | \"\n",
    "                f\"valid ppl {valid_metrics['perplexity']:.2f} | \"\n",
    "                f\"time {train_metrics['time']:.1f}s\"\n",
    "            )\n",
    "\n",
    "        test_metrics = evaluate_lm(model, test_loader, device)\n",
    "        print(\n",
    "            f\"Test loss {test_metrics['loss']:.4f} | \"\n",
    "            f\"Test ppl {test_metrics['perplexity']:.2f} | \"\n",
    "            f\"Test token acc {test_metrics['token_acc']:.2%}\"\n",
    "        )\n",
    "\n",
    "        sample = generate_text(\n",
    "            model,\n",
    "            prompt='the meaning of life is',\n",
    "            stoi=stoi,\n",
    "            itos=itos,\n",
    "            device=device,\n",
    "            max_len_ctx=config['max_len'],\n",
    "            max_new_tokens=30,\n",
    "            temperature=1.0,\n",
    "        )\n",
    "        print('Sample generation:', sample)\n",
    "\n",
    "        results[depth] = {\n",
    "            'n_params': n_params,\n",
    "            'train_losses': train_losses,\n",
    "            'valid_losses': valid_losses,\n",
    "            'valid_ppls': valid_ppls,\n",
    "            'test_loss': test_metrics['loss'],\n",
    "            'test_perplexity': test_metrics['perplexity'],\n",
    "            'test_token_acc': test_metrics['token_acc'],\n",
    "            'sample_text': sample,\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print('Experiment runner defined')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('PYTORCH WIKITEXT-2 EXPERIMENT')\n",
    "print('=' * 60)\n",
    "\n",
    "results = run_pytorch_experiment(CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(results, os.path.join(OUTPUT_DIR, 'pytorch_wikitext2_results.json'))\n",
    "\n",
    "plot_depth_comparison(\n",
    "    results,\n",
    "    CONFIG,\n",
    "    os.path.join(OUTPUT_DIR, 'pytorch_wikitext2_depth_curves.png'),\n",
    ")\n",
    "\n",
    "plot_final_metrics(\n",
    "    results,\n",
    "    os.path.join(OUTPUT_DIR, 'pytorch_wikitext2_final_metrics.png'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 60)\n",
    "print('EXPERIMENT COMPLETE')\n",
    "print('=' * 60)\n",
    "print('\\nResults saved to:', OUTPUT_DIR)\n",
    "print('\\nGenerated files:')\n",
    "for f in sorted(os.listdir(OUTPUT_DIR)):\n",
    "    path = os.path.join(OUTPUT_DIR, f)\n",
    "    if os.path.isfile(path):\n",
    "        size_kb = os.path.getsize(path) / 1024\n",
    "        print(f'  - {f} ({size_kb:.1f} KB)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: copy results to Google Drive (if mounted)\n",
    "# import shutil\n",
    "# drive_dir = '/content/drive/MyDrive/wikitext2_results'\n",
    "# shutil.copytree(OUTPUT_DIR, drive_dir, dirs_exist_ok=True)\n",
    "# print(f'Results copied to Drive: {drive_dir}')\n",
    "\n",
    "print('To copy results to Drive, mount Drive and uncomment this cell.')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "qZWC_MgV0tFV",
    "8nVJH_cK0tFX",
    "p3S_Yf5_0tFZ",
    "2z_yqIVT0tFb"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}